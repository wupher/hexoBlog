title: MongoDB Monkey测试报告
date: 2015-03-12
tags: mongodb
---

# MongoDB Monkey测试报告

## 环境
* 机型： DELL R720
* CPU ： 逻辑CPU 24
* 内存： 32GB
* 硬盘： 3 Disk 300GB For Linux, 300GB for DB file, 300GB for data backup
* 操作系统: CentOS 6.6
* Kernel版本： Linux version 2.6.32-431.el6.x86_64 
* 测试套件：使用YCSB对MongoDB Replica Set进行压测同时释放Monkey来测试服务HA


## CPU占用25%

* 结论：CPU占用对 MongoDB 测试影响不大

* YCSB: 50线程并发， 200万次操作 

* TPS: 10050.503781502048

多写少读情景

| 平均延迟时间(us) | 最小延迟时间(us) | 最大延迟时间(us) | 95%情况下的延迟(ms) | 99%情况下的延迟(ms)|
|-----|--------------|--------------|--------------|-------|--------------------|
| 4848.170762034163 |376|127838| 7 | 8 |


多读少写情况    


| 平均延迟时间(us) | 最小延迟时间(us) | 最大延迟时间(us) | 95%情况下的延迟(ms) | 99%情况下的延迟(ms) |
|-----|--------------|--------------|--------------|-------|--------------------|
| 4364.279919380055 | 371 | 143865 | 6 | 7 |



## CPU 占用 50%
* 结论： CPU占用对 MongoDB 测试影响不大
* YCSB:  50线程并发 2千万次操作
* TPS:    10075.140397081434

多写少读场景

| 平均延迟时间(us) | 最小延迟时间(us) | 最大延迟时间(us) | 95%情况下的延迟(ms) | 99%情况下的延迟(ms)|  
|-----|--------------|--------------|--------------|-------|--------------------|   
|4743.959034460835| 458 | 264973 | 7 | 8 |

多读少写场景

| 平均延迟时间(us) | 最小延迟时间(us) | 最大延迟时间(us) | 95%情况下的延迟(ms) | 99%情况下的延迟(ms)|
|-----|--------------|--------------|--------------|-------|--------------------|
| 4283.150683410138 | 374 | 219316 | 7 | 7 |


---

## 网络延迟
* 结论： 网络延迟对MongoDB的性能会造成显著影响
* 报警： icinga MongoDB监控会监测到Replicat Set间通讯超时，发出报警
* YCSB： 50线程 30万次操作（因为实在太慢了，所以不得不降低操作数）
* TPS ： 227.8660421111637

多写少读

| 平均延迟时间(us) | 最小延迟时间(us) | 最大延迟时间(us) | 95%情况下的延迟(ms) | 99%情况下的延迟(ms)|
|-----|--------------|--------------|--------------|-------|--------------------|
| 246228.77590738214 | 200329 | 1881540 | 441 | 443|

多读少写

| 平均延迟时间(us) | 最小延迟时间(us) | 最大延迟时间(us) | 95%情况下的延迟(ms) | 99%情况下的延迟(ms)|
|-----|--------------|--------------|--------------|-------|--------------------|
| 200850.83732000698 | 200368 | 1692479 | 201 | 201|


---

## 网络丢包

* 结论： 网络丢包会对MongoDB的性能造成显著影响
* 报警： 目前的icinga上还没有任何针对网络丢包的检查，不会有任何报警，而且由于是随机丢包 Relipca Set间通讯正常，也显示正常
* 场景： 随机丢掉20% ，成功率为25%，涂清平的解释为100个包，有20个会触发丢包，其实20个有25%，5个包会掉
* YCSB:  50线程 200万次操作（因为实在太慢了，不得不降低操作数）
* TPS：  1587.2537177450204

多写少读

| 平均延迟时间(us) | 最小延迟时间(us) | 最大延迟时间(us) | 95%情况下的延迟(ms) | 99%情况下的延迟(ms)|
|-----|--------------|--------------|--------------|-------|--------------------|
| 44620.542459915465 | 273 | 8462656 | 227 | 603 |

多读少写

| 平均延迟时间(us) | 最小延迟时间(us) | 最大延迟时间(us) | 95%情况下的延迟(ms) | 99%情况下的延迟(ms)|
|-----|--------------|--------------|--------------|-------|--------------------|
| 27114.140949905286 | 353 | 12663955 | 201 | 602 |



## 强行中断服务进程
 * 结论： 目前 MongoDB 有守护进程进行守护，单纯的 KILL 要么无法杀死进程要么杀死后，服务会自动重启，不会造成显著影响；双机Replica Set场景下，持续中断（即不停的杀死），Replica切换可能最长会需要数分钟内方可切换；三机Replica Set场景下，持续中断时，Primary结点仅需数秒钟即可切换。无论哪种场景，Replica Set均保证数据不会丢失，强行中断服务进程仅影响服务访问。
 * YCSB:  50线程 200万次操作
 * TPS： 9279.278443308249

 多写少读
 
| 平均延迟时间(us) | 最小延迟时间(us) | 最大延迟时间(us) | 95%情况下的延迟(ms) | 99%情况下的延迟(ms)|
|-----|--------------|--------------|--------------|-------|--------------------|
| 5125.658795371358 | 386 | 10119634 |　7　|　１０　|


多读少写

| 平均延迟时间(us) | 最小延迟时间(us) | 最大延迟时间(us) | 95%情况下的延迟(ms) | 99%情况下的延迟(ms) |
|-----|--------------|--------------|--------------|-------|--------------------|
| 4764.85681060853 | 382 | 10139386 | 7 | 9 |


---

## 内存占用试验
* 结论：内存占用，尤其是大量占用对数据库性能造成显著影响，事实上，对整个操作系统都造成了显著的性能影响。测试期间，涂清平的猴子强占了系统的全部内存，并且是不断的申请，回收，释放，除了内存之外，CPU消耗也很可观。    
* YCSB： 50线程 300万次操作
* TPS： 4406.994782118178

多写少读

| 平均延迟时间(us) | 最小延迟时间(us) | 最大延迟时间(us) | 95%情况下的延迟(ms) | 99%情况下的延迟(ms)|
|-----|--------------|--------------|--------------|-------|--------------------|
|  15387.080226060367 | 458 | 4237641 | 50 | 214 |

多读少写

| 平均延迟时间(us) | 最小延迟时间(us) | 最大延迟时间(us) | 95%情况下的延迟(ms) | 99%情况下的延迟(ms)|
|-----|--------------|--------------|--------------|-------|--------------------|
| 9433.753524803791 | 344 | 5633288 | 14 | 164 |

## 数据文件删除
* 结论：运行时删除 mongodb 的数据库文件与 journey 文件带来的影响是毁灭性的。数据库服务仍然运行，但是由于文件被破坏，所有的写入与 journey 都会失败。幸运的是，驱动与primary仍然会将请求同步到 secondary 上，保证数据不会丢失。服务重启或者手工触发结点切换后，Replica Set 会保证数据被同步，因为数据一致性不受影响。icinga 目前配置的数据文件检查及 MongoDB 本身都会触发报警，但遗憾的是 Replica Set自身不会对这种情况来自动触发切换。
* 此 Monkey 测试基本不影响测试性能，主要针对服务可用性进行测试。

## 磁盘文件占满
* 结论：磁盘文件占满对 MongoDB 服务带来的影响是毁灭性的。数据库服务仍然运行，仍然可通过驱动进行连接进行插入与查询。但此时数据与 journey 均无法正确写入。幸运的是，Primary

## 修改系统时间


## DNS染污

## 路由黑洞

## iptable 删除

## 总结
以上各种测试情况，TPS由高到底排列为：

| 序号 | 名称 | TPS | 可用性 | 数据一致性 |
|-------|---|----:|-----:| -----: |
| 1 | CPU 占用50% | 10075.1404 | 服务可用 | 一致 |
| 2 | CPU 占用25% | 10050.5038 | 服务可用 | 一致 |
|３ | 强行持续中断服务 | 9279.2785 | 支持自动监控报警, 数秒或数分钟自动切换主从[^1] | 一致|
| 4 | 内存占用100% | 4406.9948 | 服务可用，切换需数秒钟，且不影响服务运行 | 一致 |
| 5 | 网络丢包 | 1587.2538 | 服务基本可用，无法监控报警，切换仅需数秒 | 一致 |
| 6 | 网络延迟200ms| 227.8660 | 服务基本可用，支持自动监控报警，切换需数秒钟，且不影响服务 | 一致 |
| 7 | 数据文件删除 | -- | 支持自动监控报警,服务完全不可用，需要数秒来人工触发主从切换 | 不一致 |
| 8 | 磁盘占满 | -- | 服务假活，支持自动监控报警 | 不一致 |
| 9 | 修改系统时间| -- |  服务可用 |可能会影响一致性|
| 10| DNS污染 | -- | 服务可用 | 一致 |
| 11| 路由黑洞| -- | 支持自动监控报警, 数秒或数分钟自动切换主从[^1] | 一致 |
| 12| iptable污染| -- | 支持自动监控报警，数秒或数分钟自动切换主从[^1] | 一致 |


其中，CPU占用对DB性能造成的影响较少，系统的瓶颈目前主要在磁盘而非CPU上。强行中断服务会使系统在数秒内由于主从切换造成服务不可用，系统会在数秒内自动切换主从，切换其间客户端无法连接服务。中断服务仅对服务可用性造成影响，与系统性能无关。内存占用，会显著降低操作系统以及DB性能，造成系统响应缓慢，而且主从不会因为内存占用而自动进行切换。网络丢包与网络延迟对DB的影响最大，而且网络丢包基本在DB端很难发现，最好能配置专用探测与报警工具。


---
[^1]: 这与Replica Set从结点的数量级有关。2版本以后的Replica Set，Secondary在Primary当机后，会发起一个投票过程，Secondary们根据投票结果“选举”出一台新的Primary。可以通过设置Priority来优化这一投票过程，使得投票更快。通过这一过程仅需要一至三秒钟即可。不幸的是，当仅有一台Secondary时，Secondary并不会直接自动切换成Primary。它会一直尝试发起投票，直到数分钟超时后仍未收到投票回复，才会切换成Primary。     		
[^2]: icinga 有相关监控，报警后，可通过命令或者`Salt`来强制切换主从，切换过程一般仅需数秒			
[^3]: icinga 无法或者暂时没有相关监控，可通过命令或者`Salt`来强制切换主从，切换过程一般仅需数秒			
[^4]: MongoDB在做oplog同步与主从切换时会比较最后同步时间，此时间不一致会影响failover的Rollback，及oplog sync。目前测试的机器已经配置了NTP，因此基本不受影响。icinga的监控也会打印出最后同步时间。		
[^5]: 磁盘100%后，icinga检查及MongoDB都会报错（oplog/journey can't write），但是用户此时仍然可以进行查询与插入操作。Secondary仍会同步数据（假如从机的硬盘空间仍有冗余）      
[^6]: 磁盘文件删除后，icinga检查会报错，但是 MongoDB 本身仍然在提供服务！在数据容量小于内存容量时，从用户角度看，服务仍然正常，收到的请求也会同步到secondary。但是 Primary此时无法写入数据与journey。重启或者手工切换后，服务正常，数据也不会丢失。     
[^7]: MongoDB一般使用主机名或者IP地址进行配置，因此与DNS关系不大。Seconday与Primary之间的连接在icinga中有配置监控，当Primary无法访问时，Replica Set会自动切换，一般切换耗时一至数秒钟。












